{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First three blocks are installs / imports for libraries"
      ],
      "metadata": {
        "id": "IeFesK6seVJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCY2WP69qxRE",
        "outputId": "5321275c-aba0-4294-f481-b78bf84efc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.171.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FSI9v_Rgmuk",
        "outputId": "06bcb5bc-cdff-405d-ae84-0d5fcd79b938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 python-docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "import PyPDF2 # For PDF files | Probably don't need\n",
        "import docx # For .docx Word files | Probably don't need\n",
        "from IPython.display import display, Markdown, clear_output # For better Colab output\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from google.genai import types\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, clear_output # For better Colab output\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "XJowttfchOhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions"
      ],
      "metadata": {
        "id": "0RRaT6Uvix8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "#Names of the models for each part\n",
        "text_gen_model = \"gemini-1.5-flash\"\n",
        "image_gen_model = \"gemini-2.0-flash-preview-image-generation\"\n",
        "#image_gen_model = \"gemini-2.0-flash-exp-image-generation\"\n",
        "\n",
        "#Extracts text from a text (.txt) file\n",
        "def get_txt(txt_path):\n",
        "    \"\"\"Extracts text from a plain text file.\"\"\"\n",
        "    try:\n",
        "        with open(txt_path, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"Error: Could not decode text file '{txt_path}' with UTF-8. Trying with 'latin-1'.\")\n",
        "        with open(txt_path, 'r', encoding='latin-1') as file:\n",
        "            return file.read()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading text file '{txt_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "#Given an image path, loads an image\n",
        "def get_img(img_path):\n",
        "  try:\n",
        "    style_ex = Image.open(img_path)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: {img_path} could not be found. Please try again\")\n",
        "    style_ex = Image.new('RGB', (100, 100), color = 'red')\n",
        "    print(\"Creating replacement image, result will not be styled properly\")\n",
        "\n",
        "  return style_ex\n",
        "\n",
        "def create_note(img_path):\n",
        "  my_file = client.files.upload(file=img_path)\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[my_file, \"Caption this image in a detailed manner. Make sure to point out characters and make descriptions about them.\"],\n",
        "    )\n",
        "  return(response.text)\n",
        "\n",
        "def check_empty(text):\n",
        "  text_list = text.split(\" \")\n",
        "  test2 = \"\".join(map(str, text_list))\n",
        "  if test2 == \"\":\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "Fp0yOPi2ir8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempting to print more than 3 images in one function call"
      ],
      "metadata": {
        "id": "SX71PqEnkNjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_story(panels: dict):\n",
        "  uneven = False\n",
        "  rows = len(panels.keys()) // 3\n",
        "  if len(panels.keys()) % 3 != 0:\n",
        "    uneven = True\n",
        "\n",
        "  for i in range(0, rows):\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 8)) # Create a figure and three subplots\n",
        "\n",
        "    img1 = Image.open(panels[(i*3)][1]).convert(\"RGB\")\n",
        "    img1 = img1.resize((300,200))\n",
        "    ax1.imshow(img1)\n",
        "    ax1.axis(\"off\")\n",
        "    ax1.text(0.5, -0.1, f\"{panels[(i*3)][0]}\", ha=\"center\", va=\"top\", transform=ax1.transAxes)\n",
        "\n",
        "    img2 = Image.open(panels[(i*3)+1][1]).convert(\"RGB\")\n",
        "    img2 = img2.resize((300,200))\n",
        "    ax2.imshow(img2)\n",
        "    ax2.axis(\"off\")\n",
        "    ax2.text(0.5, -0.1, f\"{panels[(i*3)+1][0]}\", ha=\"center\", va=\"top\", transform=ax2.transAxes)\n",
        "\n",
        "    img3 = Image.open(panels[(i*3)+2][1]).convert(\"RGB\")\n",
        "    img3 = img3.resize((300,200))\n",
        "    ax3.imshow(img3)\n",
        "    ax3.axis(\"off\")\n",
        "    ax3.text(0.5, -0.1, f\"{panels[(i*3)+2][0]}\", ha=\"center\", va=\"top\", transform=ax3.transAxes)\n",
        "\n",
        "    plt.tight_layout() # Adjust layout to prevent text overlap\n",
        "    plt.show()\n",
        "\n",
        "  if uneven:\n",
        "    columns = len(panels.keys()) % 3\n",
        "    last_keys = list(panels.keys())[-1 * columns:]\n",
        "    if columns == 1:\n",
        "      fig, (ax1) = plt.subplots(1, 1, figsize=(15,8))\n",
        "\n",
        "      img1 = Image.open(panels[last_keys[0]][1]).convert(\"RGB\")\n",
        "      img1 = img1.resize((300,200))\n",
        "      ax1.imshow(img1)\n",
        "      ax1.axis(\"off\")\n",
        "      ax1.text(0.5, -0.1, f\"{panels[last_keys[0]][0]}\", ha=\"center\", va=\"top\", transform=ax1.transAxes)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "    elif columns == 2:\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,8))\n",
        "\n",
        "      img1 = Image.open(panels[last_keys[0]][1]).convert(\"RGB\")\n",
        "      img1 = img1.resize((300,200))\n",
        "      ax1.imshow(img1)\n",
        "      ax1.axis(\"off\")\n",
        "      ax1.text(0.5, -0.1, f\"{panels[last_keys[0]][0]}\", ha=\"center\", va=\"top\", transform=ax1.transAxes, wrap = True)\n",
        "\n",
        "      img2 = Image.open(panels[last_keys[1]][1]).convert(\"RGB\")\n",
        "      img2 = img2.resize((300,200))\n",
        "      ax2.imshow(img2)\n",
        "      ax2.axis(\"off\")\n",
        "      ax2.text(0.5, -0.1, f\"{panels[last_keys[1]][0]}\", ha=\"center\", va=\"top\", transform=ax2.transAxes, wrap = True)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "-igglRRSkK-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative Functions"
      ],
      "metadata": {
        "id": "zrmRcMqcl5p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Text Generation | Programmed so that it can generate a story, and a title for the story.\n",
        "The function needs to be called separately for generating both.\n",
        "Parameters:\n",
        "- out_type : \"STORY\" by default, generates the story : \"TITLE\" generates a story based on the 'prompt' input\n",
        "- form : Changes the end of the prompt by specifying how the model should interpret the example text. Refer to the 'forms' dictionary\n",
        "- prompt : if out_type is \"STORY\", insert the prompt for the story : if out_type is \"TITLE\", insert the story\n",
        "- ex_txt : Example text to be used for the story's format (ONLY ONE) : Value doesn't matter when out_type is \"TITLE\"\n",
        "- count : When out_type is \"STORY\", the story will be exactly 'count' sentences long : When out_type is \"TITLE\", the title will be exactly 'count' words long\n",
        "\"\"\"\n",
        "def GenText(prompt, ex_txt, count, out_type=\"STORY\", form=\"INSPIRED\"):\n",
        "  forms = {\"INSPIRED\": \"inspired by this style\", \"COPIED\": \"using this style\", \"SIMILAR\": \"in a form similar to this style\"}\n",
        "  if out_type.upper() == \"STORY\":\n",
        "    print(\"WRITE STORY\")\n",
        "    final_prompt = (f\"\"\"\n",
        "      Please use the following text as a style and tone guide:\n",
        "      ---\n",
        "      {ex_txt}\n",
        "      ---\n",
        "\n",
        "      Now, {forms[form]}, write a short story in {count} sentences, each sentence on a new line, about: {prompt}\n",
        "    \"\"\")\n",
        "  elif out_type.upper() == \"TITLE\":\n",
        "    print(\"MAKAE TITLE\")\n",
        "    final_prompt = (f\"\"\"\n",
        "      Please read the following children story, and create a title for it that is exactly {count} words: {prompt}\n",
        "    \"\"\")\n",
        "  elif out_type.upper() == \"SETTING\":\n",
        "    print(\"DESC SETTING\")\n",
        "    final_prompt = (f\"\"\"\n",
        "      Please read the following children story and describe the setting where it would be taking place: {prompt}\n",
        "    \"\"\")\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model = text_gen_model,\n",
        "      contents = final_prompt,\n",
        "      config = types.GenerateContentConfig(\n",
        "          response_modalities=['TEXT', 'Text']\n",
        "      )\n",
        "  )\n",
        "  return response\n",
        "\n",
        "\"\"\"\n",
        "Image Generation | Generates an image\n",
        "Parameters:\n",
        "- prompt : The text prompt to create an image from\n",
        "- ex_img : The image fed into the model as a style example (ONLY ONE IMAGE)\n",
        "- file_name : File name for the generated image to be saved by, saved by \"TEST.png\" be default\n",
        "- notes : To specify more about the prompt that isn't implied in the prompt already, since we're feeding sentences into the function\n",
        "\"\"\"\n",
        "\n",
        "def GenImage(prompt, setting, ex_img, file_name = \"TEST.png\", note = \"\"):\n",
        "  final_prompt = f\"\"\"In a style inspired by the provided image, create an image for this caption: {prompt}\n",
        "  The image should keep the following setting in mind: {setting}\n",
        "  Use this provided note to guide you and what has happened, and who is who: {note}\n",
        "  Feel free to change the character positions and background elements, just maintain a consistent art style.\n",
        "  the notes are meant as a reference to make sure everything is correct.\n",
        "  You can change details in your images as long as they make sense contextually.\n",
        "  \"\"\"\n",
        "  feed = (final_prompt, ex_img)\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model = image_gen_model,\n",
        "      contents = feed,\n",
        "      config = types.GenerateContentConfig(\n",
        "          response_modalities=['TEXT', \"IMAGE\"]\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  for part in response.candidates[0].content.parts:\n",
        "    if part.text is not None:\n",
        "      print(part.text)\n",
        "    elif part.inline_data is not None:\n",
        "      image = Image.open(BytesIO((part.inline_data.data)))\n",
        "      image.save(file_name)\n",
        "      image.show()\n",
        "\n",
        "\"\"\"\n",
        "Image Generation With Multiple Examples\n",
        "Parameters:\n",
        "- prompt : The text prompt to create an image from\n",
        "- ex_imgs : A list of images fed into the model as a style example (MULTIPLE ALLOWED | CAN DO ONE)\n",
        "\"\"\"\n",
        "def GenImage_FromList(prompt, setting, ex_imgs, file_name = \"TEST.png\", note=\"\"):\n",
        "  final_prompt = f\"\"\"In a style inspired by the provided image, create an image for this caption: {prompt}\n",
        "  The image should keep the following setting in mind: {setting}\n",
        "  Use this provided note to guide you and what has happened, and who is who: {note}\n",
        "  Remember to change the character positions and background elements, and maintain a consistent art style.\n",
        "  Changes in background elements should make sense contextually\n",
        "  The notes are meant as a reference to ensure proper continuity.\n",
        "  \"\"\"\n",
        "  feed = tuple([final_prompt] + ex_imgs)\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model = image_gen_model,\n",
        "      contents = feed,\n",
        "      config = types.GenerateContentConfig(\n",
        "          response_modalities=['TEXT', \"IMAGE\"]\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  for part in response.candidates[0].content.parts:\n",
        "    if part.text is not None:\n",
        "      print(part.text)\n",
        "    elif part.inline_data is not None:\n",
        "      image = Image.open(BytesIO((part.inline_data.data)))\n",
        "      image.save(file_name)\n",
        "      image.show()"
      ],
      "metadata": {
        "id": "9gDGufYil7Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generates the story\n",
        "text_sample = get_txt(\"/content/drseuss.txt\")\n",
        "story_prompt = \"A frog goes to a waterpark for a day, and meets a cute toad\"\n",
        "#story_prompt = input(\"Enter a prompt to create a tale: \")\n",
        "story = GenText(story_prompt, text_sample, 9)\n",
        "\n",
        "for part in story.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    story_str = part.text\n",
        "\n",
        "story_list_check = story_str.splitlines()\n",
        "story_list = []\n",
        "for i in story_list_check:\n",
        "  if not check_empty(i):\n",
        "    story_list.append(i)\n",
        "#Prints the story line by line\n",
        "for i in range(0, len(story_list)):\n",
        "  print(str(i) + \": \" + story_list[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ULsFCh4lwvOq",
        "outputId": "c382b2c9-89e8-432e-ab07-54e481715719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not decode text file '/content/drseuss.txt' with UTF-8. Trying with 'latin-1'.\n",
            "WRITE STORY\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ServerError",
          "evalue": "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServerError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8148390>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstory_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"A frog goes to a waterpark for a day, and meets a cute toad\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#story_prompt = input(\"Enter a prompt to create a tale: \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-2949312381>\u001b[0m in \u001b[0;36mGenText\u001b[0;34m(prompt, ex_txt, count, out_type, form)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\")\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   response = client.models.generate_content(\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_gen_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5956\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5957\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5958\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   5959\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5960\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4919\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4921\u001b[0;31m     response_dict = self._api_client.request(\n\u001b[0m\u001b[1;32m   4922\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     )\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       )\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m       return HttpResponse(\n\u001b[1;32m    696\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServerError\u001b[0m: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generates a title and prints it\n",
        "title = GenText(story_str, None, 5, out_type=\"TITLE\")\n",
        "\n",
        "for part in title.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    final_title = part.text\n",
        "\n",
        "print(final_title)"
      ],
      "metadata": {
        "id": "ujtDJFGJdFOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setting = GenText(story_str, None, None, out_type=\"SETTING\")\n",
        "for part in setting.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    final_setting = part.text\n",
        "\n",
        "print(final_setting)"
      ],
      "metadata": {
        "id": "lXkbiiaC5IWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the 'note' variable each time you generate an image for the caption. Some 'story relevant' info isn't implied in the caption, and the model will output a funky result"
      ],
      "metadata": {
        "id": "MWl7tGlYY-Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gets an image and generates a new one\n",
        "img_sample = get_img(\"/content/brown3.jpg\")\n",
        "notes = \"\"\n",
        "panels = {}\n",
        "images = [img_sample]\n",
        "for i in range(0, len(story_list)):\n",
        "  GenImage_FromList(story_list[i], setting, images, note=notes, file_name=\"OUT\" + str(i) + \".png\")\n",
        "  #GenImage(story_list[i], final_setting, img_sample, file_name = \"OUT\" + str(i) + \".png\", note=notes)\n",
        "  panels[i] = [story_list[i] ,\"OUT\" + str(i) + \".png\"]\n",
        "  images.append(get_img(panels[i][1]))\n",
        "  if len(images) >= 4:\n",
        "    del images[0]\n",
        "  notes = notes + \" afterwards: \" + create_note(\"OUT\" + str(i) + \".png\")"
      ],
      "metadata": {
        "id": "bkJh726zOOEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_story(panels)"
      ],
      "metadata": {
        "id": "fxv73m_oj2dw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}